{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "u_cols=['user id',\"age\",\"sex\",\"occupation\",\"zip_score\"]\n",
    "users=pd.read_csv(\"u.user\",sep='|',names=u_cols)\n",
    "\n",
    "r_cols =['user id',\"movie id\",\"rating\",\"timestamp\"]\n",
    "ratings=pd.read_csv(\"u.data\",sep='\\t',names=r_cols)\n",
    "\n",
    "i_cols = ['movie id','movie title','release date','video release date','IMDb URL','Unknown','action','adventure','Animation',\n",
    "          'children','comedy','crime','documentrty','drama','fantasy','film-noir','horror','musical','mystery','Roamance',\n",
    "          'Sci-Fi','Triller','war','western']\n",
    "movies_title= pd.read_csv(\"u.item\", sep=\"|\",header= None,names = i_cols, encoding = 'latin-1')\n",
    "\n",
    "df=pd.merge(ratings,movies_title,on=\"movie id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = pd.DataFrame(df.groupby('user id').count()['movie id'])\n",
    "\n",
    "plt.hist(ratings1['movie id'], bins=70)\n",
    "plt.xlabel('No of users')\n",
    "plt.ylabel('no of movies rated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2= pd.DataFrame(df.groupby('movie title').count()['rating'])\n",
    "\n",
    "plt.hist(ratings2['rating'],bins=70)\n",
    "plt.xlabel('movie')\n",
    "plt.ylabel('no of ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate count the average number of nullatings for all users\n",
    "#df2 = df.C.isnull().groupby([df['A'],df['B']]).sum().astype(int).reset_index(name='count')\n",
    "null_rat = df.groupby('user id').agg({'rating': lambda x: x.isnull().count()})\n",
    "null_rat['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User-user & item-item based recommendations\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_columns = ['user_id','age','sex','occupation','zip_code']\n",
    "users = pd.read_csv('u.user', sep='|', names = u_columns, encoding='latin-1',skiprows=1)\n",
    "\n",
    "r_columns = ['user_id','movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('u.data', sep='\\t', names=r_columns,encoding='latin-1',skiprows=1)\n",
    "\n",
    "i_columns = ['movie_id','movie_title','release_date','video_release_date','IMDb_url','unknown','Action','Adventure','Animation','Children','Comedy','Crime','Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western']\n",
    "items = pd.read_csv('u.item', sep='|', names=i_columns,encoding='latin-1',skiprows=1)\n",
    "\n",
    "dd = defaultdict(list)\n",
    "\n",
    "usersList = users.to_dict('records',into=dd)\n",
    "usersList.append({'user_id':1})\n",
    "ratingsList = ratings.to_dict('records',into=dd)\n",
    "itemsList = items.to_dict('records',into=dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = defaultdict(lambda: 0)\n",
    "movie_dict = defaultdict(lambda: 0)\n",
    "\n",
    "for i,cell in enumerate(ratingsList):\n",
    "    user_dict[cell['user_id']] +=1\n",
    "    movie_dict[cell['movie_id']] +=1\n",
    "    \n",
    "def return_len(item):\n",
    "    return item[1]\n",
    "\n",
    "movielist = sorted(movie_dict.items(), key=return_len)    \n",
    "userlist = sorted(user_dict.items(), key=return_len)\n",
    "\n",
    "\n",
    "movie_distribution = [item for item in map(lambda x: x[1], movielist)]\n",
    "user_distribution = [item for item in map(lambda x: x[1], userlist)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-User Collaborative Filtering\n",
    "def create_userMovieRatingTable(usersList,ratingsList):\n",
    "    userMovieTable = defaultdict(lambda: defaultdict())\n",
    "\n",
    "    for j, rating in enumerate(ratingsList):\n",
    "        userMovieTable[rating['user_id']][rating['movie_id']] = rating['rating']\n",
    "        \n",
    "    return userMovieTable, i+1 ,j+1\n",
    "\n",
    "def get_min_max_movies(userMovieDict):\n",
    "    userMinMaxMovieDict = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for user, movieList in userMovieDict.items():\n",
    "        if(len(movieList) > 0):\n",
    "            userMinMaxMovieDict[user]['min'] = min(movieList.keys())\n",
    "            userMinMaxMovieDict[user]['max'] = max(movieList.keys())\n",
    "        else:\n",
    "            userMinMaxMovieDict[user]['min'] = 0\n",
    "            userMinMaxMovieDict[user]['max'] = 1642\n",
    "    \n",
    "    return userMinMaxMovieDict\n",
    "\n",
    "def createSimilarityMatrix(userMovieDict,similarityMoviesValues):\n",
    "    userSimilarityDict = defaultdict(lambda: defaultdict())\n",
    "    \n",
    "    for user1,movies_rated_user1 in userMovieDict.items():\n",
    "        for user2,movies_rated_user2 in userMovieDict.items():\n",
    "            if((len(similarityMoviesValues[user1][user2]['ratings_user1']) > 1) and (user1 !=user2)):\n",
    "                userSimilarityDict[user1][user2] = pearson_coefficients(similarityMoviesValues[user1][user2]['ratings_user1'],similarityMoviesValues[user1][user2]['ratings_user2'],similarityMoviesValues[user1][user2]['mean_ratings_user1'],similarityMoviesValues[user1][user2]['mean_ratings_user2'])\n",
    "    \n",
    "    return userSimilarityDict\n",
    "    \n",
    "def similar_movies_recommended(userMovieDict):\n",
    "    similarMoviesDict = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for user1,movies_rated_user1 in userMovieDict.items():\n",
    "        for user2,movies_rated_user2 in userMovieDict.items():\n",
    "            for movie_user1 in movies_rated_user1.keys():\n",
    "                if(movie_user1 in movies_rated_user2.keys()):\n",
    "                    similarMoviesDict[user1][user2].append(movie_user1)\n",
    "    \n",
    "    return similarMoviesDict\n",
    "\n",
    "def get_average_user_rating(userMovieRating):\n",
    "    averageUserRating = defaultdict()\n",
    "    \n",
    "    for user1,movies_rated_user1 in userMovieRating.items():\n",
    "        val_list = movies_rated_user1.values()\n",
    "        averageUserRating[user1] = np.mean([item for item in val_list])\n",
    "    \n",
    "    return averageUserRating\n",
    "\n",
    "def generate_similarity_matrix(similarMoviesDict,userMovieRating,average_user_rating):\n",
    "    similarMoviesItemsDict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    \n",
    "    for user1,similar_user_list in similarMoviesDict.items():\n",
    "        for user2, common_movies in similar_user_list.items():\n",
    "            for movie in common_movies:\n",
    "                similarMoviesItemsDict[user1][user2]['ratings_user1'].append(userMovieRating[user1][movie])\n",
    "                similarMoviesItemsDict[user1][user2]['ratings_user2'].append(userMovieRating[user2][movie])\n",
    "            \n",
    "            similarMoviesItemsDict[user1][user2]['mean_ratings_user1'] = average_user_rating[user1]\n",
    "            similarMoviesItemsDict[user1][user2]['mean_ratings_user2'] = average_user_rating[user2]\n",
    "            \n",
    "            \n",
    "    return similarMoviesItemsDict\n",
    "    \n",
    "def pearson_coefficients(val_user1,val_user2,mean_user1,mean_user2):\n",
    "    numerator_diff_user1 = 0\n",
    "    numerator_diff_user2 = 0\n",
    "    numerator_prod = 0\n",
    "    \n",
    "    denominator_prod1 = 0\n",
    "    denominator_prod2 = 0\n",
    "    \n",
    "    for i, valUser1 in enumerate(val_user1):\n",
    "        numerator_diff_user1 = valUser1 - mean_user1\n",
    "        numerator_diff_user2 = val_user2[i] - mean_user2\n",
    "        numerator_prod += (numerator_diff_user1 * numerator_diff_user2)\n",
    "        \n",
    "        denominator_prod1 += (math.pow(numerator_diff_user1,2))\n",
    "        denominator_prod2 += (math.pow(numerator_diff_user2,2))\n",
    "    \n",
    "    sqrt_denominator = math.sqrt(denominator_prod1*denominator_prod2)\n",
    "    \n",
    "    if(sqrt_denominator !=0):\n",
    "        weight = numerator_prod/sqrt_denominator\n",
    "    else:\n",
    "        weight = 0\n",
    "    \n",
    "    return weight\n",
    "\n",
    "def sorting_dict_by_lengthVal(clusterInfo):\n",
    "    sorted_dict = sorted(clusterInfo.items(), key=comp_val, reverse=True)\n",
    "    return sorted_dict\n",
    "\n",
    "def comp_val(item):\n",
    "    return item[1]\n",
    "\n",
    "def sortDictDict(dictdict):\n",
    "    for entity1,list_other_entities in dictdict.items():\n",
    "        dictdict[entity1] = sorting_dict_by_lengthVal(list_other_entities)\n",
    "    \n",
    "    return dictdict\n",
    "\n",
    "def get_topTen(sortedDict):\n",
    "    for entity1,list_entities in sortedDict.items():\n",
    "        sortedDict[entity1] = list_entities[0:10]\n",
    "        \n",
    "    return sortedDict\n",
    "\n",
    "def get_topTenMovies(sortedDict,watchedMovieDict,userMinMaxDict,filterFlag=False):\n",
    "    topTenDict = defaultdict(list)\n",
    "    \n",
    "    for entity1,list_entities in sortedDict.items():\n",
    "        if (len(list_entities)>0):\n",
    "            for movie in list_entities:\n",
    "                if ((movie[0] not in watchedMovieDict[entity1])):\n",
    "                    if (filterFlag and (movie[0] >= userMinMaxDict[entity1]['min'] and movie[0] <= userMinMaxDict[entity1]['max'])):\n",
    "                        topTenDict[entity1].append(movie)\n",
    "                    elif (filterFlag == False):\n",
    "                        topTenDict[entity1].append(movie)\n",
    "                topTenDict[entity1] = topTenDict[entity1][0:10]\n",
    "    return topTenDict\n",
    "\n",
    "def get_estimated_movie_rating(neighborhoodDict,average_user_rating,userMovieRating,usersList,itemsList):\n",
    "    estimatedMovieTable = defaultdict(lambda: defaultdict())\n",
    "    \n",
    "    for user1 in usersList:\n",
    "        for movie in itemsList:\n",
    "            sum_numerator = 0\n",
    "            sum_denominator = 0\n",
    "            for neighborUser in neighborhoodDict[user1['user_id']]:\n",
    "                if(movie['movie_id'] in userMovieRating[neighborUser[0]].keys()):\n",
    "                    sum_numerator += neighborUser[1] * (userMovieRating[neighborUser[0]][movie['movie_id']] - average_user_rating[neighborUser[0]])\n",
    "                    sum_denominator += neighborUser[1]\n",
    "            \n",
    "            if(sum_denominator !=0 ):\n",
    "                estimatedMovieTable[user1['user_id']][movie['movie_id']] = average_user_rating[user1['user_id']] + (sum_numerator/sum_denominator)\n",
    "            else:\n",
    "                estimatedMovieTable[user1['user_id']][movie['movie_id']] = 0\n",
    "    \n",
    "    return estimatedMovieTable\n",
    "\n",
    "\n",
    "# Item-Item Collaborative Filtering\n",
    "def create_movieUserRatingTable(usersList,ratingsList):\n",
    "    movieUserTable = defaultdict(lambda: defaultdict())\n",
    "\n",
    "    for j, rating in enumerate(ratingsList):\n",
    "        movieUserTable[rating['movie_id']][rating['user_id']] = rating['rating']\n",
    "        \n",
    "    return movieUserTable, i+1 ,j+1\n",
    "    \n",
    "def similar_users_recommended(movieUserDict):\n",
    "    similarUsersDict = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for movie1,users_rated_movie1 in movieUserDict.items():\n",
    "        for movie2,users_rated_movie2 in movieUserDict.items():\n",
    "            for user_movie1 in users_rated_movie1.keys():\n",
    "                if(user_movie1 in users_rated_movie2.keys()):\n",
    "                    similarUsersDict[movie1][movie2].append(user_movie1)\n",
    "    \n",
    "    return similarUsersDict\n",
    "\n",
    "def get_average_movie_rating(movieUserRating):\n",
    "    averageMovieRating = defaultdict()\n",
    "    \n",
    "    for movie1,users_rated_movie1 in movieUserRating.items():\n",
    "        val_list = users_rated_movie1.values()\n",
    "        if(len(val_list) == 0):\n",
    "            print(movie1)\n",
    "        else:\n",
    "            averageMovieRating[movie1] = np.mean([item for item in val_list])\n",
    "    \n",
    "    return averageMovieRating\n",
    "\n",
    "def already_watched_movies(userMovieRating):\n",
    "    alreadyWatchedMovieDict = defaultdict(list)\n",
    "    \n",
    "    for userId,movie_list in userMovieRating.items():\n",
    "#         alreadyWatchedMovieDict[userId] = movie_list.keys()\n",
    "        alreadyWatchedMovieDict[userId] = []\n",
    "        \n",
    "    return alreadyWatchedMovieDict\n",
    "    \n",
    "\n",
    "def generate_similarity_movie_matrix(similarUsersDict,movieUserRating,average_movie_rating):\n",
    "    similarUsersItemsDict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "            \n",
    "    for movie1,similar_movie_list in similarUsersDict.items():\n",
    "        for movie2, common_users in similar_movie_list.items():\n",
    "            for user in common_users:\n",
    "                similarUsersItemsDict[movie1][movie2]['ratings_movie1'].append(movieUserRating[movie1][user])\n",
    "                similarUsersItemsDict[movie1][movie2]['ratings_movie2'].append(movieUserRating[movie2][user])\n",
    "            \n",
    "            similarUsersItemsDict[movie1][movie2]['mean_ratings_movie1'] = average_movie_rating[movie1]\n",
    "            similarUsersItemsDict[movie1][movie2]['mean_ratings_movie2'] = average_movie_rating[movie2]\n",
    "            \n",
    "            \n",
    "    return similarUsersItemsDict\n",
    "\n",
    "def createSimilarityMovieMatrix(movieUserDict,similarityUserValues):\n",
    "    movieSimilarityDict = defaultdict(lambda: defaultdict())\n",
    "    \n",
    "    for movie1,users_rated_movie1 in movieUserDict.items():\n",
    "        for movie2,users_rated_movie2 in movieUserDict.items():\n",
    "            if((len(similarityUserValues[movie1][movie2]['ratings_movie1']) > 1) and (movie1 !=movie2)):\n",
    "                movieSimilarityDict[movie1][movie2] = pearson_coefficients(similarityUserValues[movie1][movie2]['ratings_movie1'],similarityUserValues[movie1][movie2]['ratings_movie2'],similarityUserValues[movie1][movie2]['mean_ratings_movie1'],similarityUserValues[movie1][movie2]['mean_ratings_movie2'])\n",
    "\n",
    "    return movieSimilarityDict\n",
    "\n",
    "def get_estimated_movie_ratings_item_item(neighborhoodMovieDict,average_movie_rating,movieUserRating,usersList,itemsList):\n",
    "    estimatedMovieTable = defaultdict(lambda: defaultdict())\n",
    "    \n",
    "    for movie1 in itemsList:   \n",
    "        for user in usersList:\n",
    "            sum_numerator = 0\n",
    "            sum_denominator = 0\n",
    "            for neighborMovie in neighborhoodMovieDict[movie1['movie_id']]:\n",
    "                if(user['user_id'] in movieUserRating[neighborMovie[0]].keys()):\n",
    "                    sum_numerator += neighborMovie[1] * (movieUserRating[neighborMovie[0]][user['user_id']])\n",
    "                    sum_denominator += neighborMovie[1]\n",
    "            \n",
    "            if(sum_denominator !=0 ):\n",
    "                estimatedMovieTable[movie1['movie_id']][user['user_id']] = (sum_numerator/sum_denominator)\n",
    "            else:\n",
    "                estimatedMovieTable[movie1['movie_id']][user['user_id']] = 0\n",
    "    \n",
    "    return estimatedMovieTable\n",
    "\n",
    "def convert_movieTable_UserTable(movieUserTable):\n",
    "    estimatedUserTable = defaultdict(lambda: defaultdict())\n",
    "    \n",
    "    for movie, user_list in movieUserTable.items():\n",
    "        for user,rating in user_list.items():\n",
    "            estimatedUserTable[user][movie] = rating\n",
    "                               \n",
    "    return estimatedUserTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user-user collaborative filtering\n",
    "userMovieRating, totalUsers, totalMovies = create_userMovieRatingTable(usersList,ratingsList)\n",
    "userMinMaxDict = get_min_max_movies(userMovieRating)\n",
    "alreadyWatchedMovies = already_watched_movies(userMovieRating)\n",
    "similarMoviesDict = similar_movies_recommended(userMovieRating)\n",
    "average_user_rating = get_average_user_rating(userMovieRating)\n",
    "similarityMoviesValues = generate_similarity_matrix(similarMoviesDict,userMovieRating,average_user_rating)\n",
    "similarityMatrix = createSimilarityMatrix(userMovieRating,similarityMoviesValues)\n",
    "sortedSimilarityDict = sortDictDict(similarityMatrix)\n",
    "neighborhoodDict = get_topTen(sortedSimilarityDict)\n",
    "estimatedMovieRatings = get_estimated_movie_rating(neighborhoodDict,average_user_rating,userMovieRating,usersList,itemsList)\n",
    "sortedEstimatedMovieRatings = sortDictDict(estimatedMovieRatings)\n",
    "\n",
    "# for item-item collaborative filtering\n",
    "movieUserRating, totalUsers, totalMovies = create_movieUserRatingTable(usersList,ratingsList)\n",
    "similarUsersDict = similar_users_recommended(movieUserRating)\n",
    "average_movie_rating = get_average_movie_rating(movieUserRating)\n",
    "similarityUserValues = generate_similarity_movie_matrix(similarUsersDict,movieUserRating,average_movie_rating)\n",
    "similarityMovieMatrix = createSimilarityMovieMatrix(movieUserRating,similarityUserValues)\n",
    "sortedSimilarityMovieDict = sortDictDict(similarityMovieMatrix)\n",
    "neighborhoodMovieDict = get_topTen(sortedSimilarityMovieDict)\n",
    "estimatedMovieRatingsItemItem = get_estimated_movie_ratings_item_item(neighborhoodMovieDict,average_movie_rating,movieUserRating,usersList,itemsList)\n",
    "estimatedUserMovieRatingsItemItem = convert_movieTable_UserTable(estimatedMovieRatingsItemItem)\n",
    "sortedEstimatedMovieRatingsItemItem = sortDictDict(estimatedUserMovieRatingsItemItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(fileName,generated_dict):\n",
    "    with open(fileName, 'w') as file:\n",
    "        file.write(json.dumps(generated_dict))\n",
    "        \n",
    "topTenRecommendedUserUser = get_topTenMovies(sortedEstimatedMovieRatings,alreadyWatchedMovies,userMinMaxDict)\n",
    "save_dict('pred_user_user.txt',topTenRecommendedUserUser)\n",
    "\n",
    "topTenRecommendedItemItem = get_topTenMovies(sortedEstimatedMovieRatingsItemItem,alreadyWatchedMovies,userMinMaxDict)\n",
    "save_dict('pred_item_item.txt',topTenRecommendedItemItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content based recommendation\n",
    "df_credits = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
    "\n",
    "df_movies = pd.read_csv(\"tmdb_5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_movies,df_credits,left_on='id',right_on='movie_id')[['id','original_title','genres','keywords','overview','cast','crew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "L1=[]\n",
    "for i in ast.literal_eval('[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]'):\n",
    "    L1.append(i['name'])\n",
    "#print(L1)\n",
    "\n",
    "def convert(text):\n",
    "    L=[]\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['name'])\n",
    "        \n",
    "    L1=L[:]\n",
    "    L.clear()\n",
    "    return L1\n",
    "\n",
    "df_final['genres']=df_final['genres'].apply(convert)\n",
    "df_final['keywords']=df_final['keywords'].apply(convert)\n",
    "df_final['overview']=df_final['overview'].apply(lambda x : x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cast(text):\n",
    "    L=[]\n",
    "    counter=0\n",
    "    for i in ast.literal_eval(text):\n",
    "            if counter<3:\n",
    "                L.append(i['name'])\n",
    "            else:\n",
    "                break\n",
    "            counter+=1\n",
    "    L1=L[:]\n",
    "    L.clear()\n",
    "    return L1\n",
    "\n",
    "df_final['cast']=df_final['cast'].apply(fetch_cast)\n",
    "\n",
    "\n",
    "def fetch_director(text):\n",
    "    L=[]\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job']=='Director':\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    L1=L[:]\n",
    "    L.clear()\n",
    "    return L1\n",
    "    \n",
    "df_final['crew']=df_final['crew'].apply(fetch_director)\n",
    "\n",
    "\n",
    "df_final['tags']=df_final['genres']+df_final['keywords']+df_final['overview']+df_final['cast']+df_final['crew']\n",
    "\n",
    "def remove_space(L):\n",
    "    L1=[]\n",
    "    for i in L:\n",
    "        L1.append(i.replace(' ',''))\n",
    "    \n",
    "    L2=L1[:] \n",
    "    L1.clear()\n",
    "    return L2\n",
    "\n",
    "df_final['tags']=df_final['tags'].apply(remove_space)\n",
    "df_final['tags']=df_final['tags'].apply(lambda x:\" \".join(x))\n",
    "df_final['tags']=df_final['tags'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cv=CountVectorizer(stop_words='english',max_features=10000)\n",
    "import pickle\n",
    "pickle.dump(cv, open('cv.pkl','wb'))\n",
    "\n",
    "X = cv.fit_transform(df_final['tags']).toarray()\n",
    "similarity_matrix = cosine_similarity(X)\n",
    "pickle.dump(similarity_matrix, open('similarity_matrix.pkl','wb'))\n",
    "\n",
    "# finding the index of the movie\n",
    "df_final[df_final['original_title']=='Osama'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sorted(list(enumerate(similarity_matrix[0])),reverse=True,key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie_name):\n",
    "    movie_index=df_final[df_final['original_title']== movie_name].index[0]\n",
    "    \n",
    "    L=sorted(list(enumerate(similarity_matrix[movie_index])),reverse=True,key=lambda x:x[1])\n",
    "    \n",
    "    for i in L[1:6]:\n",
    "        print(df_final.iloc[i[0]]['original_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = input(\"Enter name of movie: \") \n",
    "recommend(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = input(\"Enter name of movie: \") \n",
    "recommend(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
